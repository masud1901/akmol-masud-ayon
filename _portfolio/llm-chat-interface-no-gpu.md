---
title: "LLM Chat Interface (CPU Optimized)"
collection: portfolio
category: research
permalink: /portfolio/llm-chat-interface-no-gpu
excerpt: 'A multi-model chat interface for LLaMA-family models and DeepSeek Coder with CPU-optimized inference.'
what_i_did: 'Built lightweight chat interface supporting LLaMA and DeepSeek models with CPU-optimized inference using llama.cpp.'
date: 2024-01-01
---

Developed a lightweight chat interface that supports multiple large language models including LLaMA variants and DeepSeek Coder. Features CPU-optimized inference using llama.cpp with optional GPU acceleration support.

**Technologies Used:** Large Language Models, Python, llama.cpp, Chat Interface

[View Project](https://github.com/masud1901/llm-chat-interface-with-no-gpu)

